{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "# import matplotlib as plt\n",
    "from random import sample\n",
    "from numpy import zeros\n",
    "from math import sqrt\n",
    "import _pickle as cPickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies = 976\n",
    "users = 6078\n",
    "reviews = 5\n",
    "active = 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = cPickle.load( open( \"dataset.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matr(shp):\n",
    "    temp = zeros(shp)\n",
    "    temp[:,0,:] = range(shp[2])\n",
    "    temp[:,:,0] = range(shp[1])\n",
    "    return temp\n",
    "\n",
    "def matr1(shp):\n",
    "    temp = zeros(shp)\n",
    "    temp[0,:] = range(shp[1])\n",
    "    temp[:,0] = range(shp[0])\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 485, 977)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate Data in Active and Passive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_gen():\n",
    "    lst = []\n",
    "    x = list(range(1,485))\n",
    "    for i in range(0,9*51,51):\n",
    "        act_rand,pass_rand = array([0] + x[i:i+active]),array([0] + x[:i] + x[active+i:])\n",
    "        active_user,passive_user = dataset[:,act_rand],dataset[:,pass_rand]\n",
    "        cPickle.dump( active_user, open( \"active_\"+ str(i) +\".pkl\", \"wb\" ) )\n",
    "        cPickle.dump( passive_user, open( \"passive_\"+ str(i)+\".pkl\", \"wb\" ) )\n",
    "        lst.append(i)\n",
    "\n",
    "    i += 51\n",
    "    act_rand,pass_rand = array([0] + x[i:]),array([0] + x[:i])\n",
    "    active_user,passive_user = dataset[:,act_rand],dataset[:,pass_rand]\n",
    "    cPickle.dump( active_user, open( \"active_\"+ str(i) +\".pkl\", \"wb\" ) )\n",
    "    cPickle.dump( passive_user, open( \"passive_\"+ str(i)+\".pkl\", \"wb\" ) )\n",
    "    lst.append(i)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   3.00000000e+00,   7.00000000e+00,\n",
       "         2.60000000e+01,   3.70000000e+01,   4.80000000e+01,\n",
       "         6.90000000e+01,   7.00000000e+01,   9.20000000e+01,\n",
       "         9.60000000e+01,   1.02000000e+02,   1.04000000e+02,\n",
       "         1.37000000e+02,   1.46000000e+02,   1.65000000e+02,\n",
       "         1.66000000e+02,   1.68000000e+02,   1.72000000e+02,\n",
       "         1.76000000e+02,   2.06000000e+02,   2.32000000e+02,\n",
       "         2.40000000e+02,   2.42000000e+02,   2.43000000e+02,\n",
       "         2.45000000e+02,   2.87000000e+02,   3.01000000e+02,\n",
       "         3.04000000e+02,   3.28000000e+02,   3.37000000e+02,\n",
       "         3.51000000e+02,   3.57000000e+02,   3.73000000e+02,\n",
       "         4.08000000e+02,   4.52000000e+02,   4.65000000e+02,\n",
       "         4.77000000e+02,   4.85000000e+02,   4.99000000e+02,\n",
       "         5.03000000e+02,   5.20000000e+02,   5.28000000e+02,\n",
       "         5.29000000e+02,   5.32000000e+02,   5.51000000e+02,\n",
       "         5.54000000e+02,   5.55000000e+02,   5.71000000e+02,\n",
       "         5.92000000e+02,   5.97000000e+02,   6.04000000e+02,\n",
       "         6.07000000e+02,   6.33000000e+02,   6.39000000e+02,\n",
       "         6.51000000e+02,   6.56000000e+02,   6.69000000e+02,\n",
       "         6.90000000e+02,   7.11000000e+02,   7.23000000e+02,\n",
       "         7.37000000e+02,   7.42000000e+02,   7.51000000e+02,\n",
       "         7.60000000e+02,   7.84000000e+02,   7.93000000e+02,\n",
       "         8.12000000e+02,   8.13000000e+02,   8.34000000e+02,\n",
       "         8.36000000e+02,   8.53000000e+02,   8.78000000e+02,\n",
       "         9.08000000e+02,   9.12000000e+02,   9.18000000e+02,\n",
       "         9.22000000e+02,   9.23000000e+02,   9.46000000e+02,\n",
       "         9.89000000e+02,   9.98000000e+02,   1.00700000e+03,\n",
       "         1.00900000e+03,   1.01700000e+03,   1.02100000e+03,\n",
       "         1.02400000e+03,   1.03900000e+03,   1.06000000e+03,\n",
       "         1.07000000e+03,   1.09300000e+03,   1.09400000e+03,\n",
       "         1.10800000e+03,   1.15400000e+03,   1.16800000e+03,\n",
       "         1.17100000e+03,   1.17600000e+03,   1.19000000e+03,\n",
       "         1.19600000e+03,   1.19800000e+03,   1.20300000e+03,\n",
       "         1.23800000e+03,   1.23900000e+03,   1.25900000e+03,\n",
       "         1.26100000e+03,   1.26200000e+03,   1.26300000e+03,\n",
       "         1.28400000e+03,   1.28600000e+03,   1.28700000e+03,\n",
       "         1.29100000e+03,   1.29300000e+03,   1.32100000e+03,\n",
       "         1.32700000e+03,   1.34400000e+03,   1.34800000e+03,\n",
       "         1.34900000e+03,   1.38500000e+03,   1.40700000e+03,\n",
       "         1.40800000e+03,   1.41900000e+03,   1.43900000e+03,\n",
       "         1.44500000e+03,   1.45800000e+03,   1.48700000e+03,\n",
       "         1.50000000e+03,   1.51000000e+03,   1.51500000e+03,\n",
       "         1.51600000e+03,   1.52100000e+03,   1.52400000e+03,\n",
       "         1.53600000e+03,   1.54800000e+03,   1.57600000e+03,\n",
       "         1.59300000e+03,   1.59900000e+03,   1.60600000e+03,\n",
       "         1.61700000e+03,   1.61800000e+03,   1.63600000e+03,\n",
       "         1.65300000e+03,   1.65600000e+03,   1.66200000e+03,\n",
       "         1.66800000e+03,   1.67600000e+03,   1.67900000e+03,\n",
       "         1.69600000e+03,   1.71300000e+03,   1.72200000e+03,\n",
       "         1.72300000e+03,   1.75200000e+03,   1.75400000e+03,\n",
       "         1.76300000e+03,   1.76500000e+03,   1.77000000e+03,\n",
       "         1.77200000e+03,   1.78600000e+03,   1.79200000e+03,\n",
       "         1.79700000e+03,   1.79800000e+03,   1.79900000e+03,\n",
       "         1.80300000e+03,   1.81400000e+03,   1.83100000e+03,\n",
       "         1.86000000e+03,   1.87600000e+03,   1.87800000e+03,\n",
       "         1.88500000e+03,   1.88600000e+03,   1.88800000e+03,\n",
       "         1.92000000e+03,   1.93600000e+03,   1.95400000e+03,\n",
       "         1.97100000e+03,   1.99400000e+03,   1.99500000e+03,\n",
       "         1.99800000e+03,   2.00500000e+03,   2.07400000e+03,\n",
       "         2.08400000e+03,   2.09200000e+03,   2.09700000e+03,\n",
       "         2.10300000e+03,   2.13400000e+03,   2.13900000e+03,\n",
       "         2.14000000e+03,   2.14500000e+03,   2.15300000e+03,\n",
       "         2.15600000e+03,   2.16500000e+03,   2.17600000e+03,\n",
       "         2.20400000e+03,   2.22200000e+03,   2.22400000e+03,\n",
       "         2.23100000e+03,   2.24100000e+03,   2.24700000e+03,\n",
       "         2.27500000e+03,   2.27600000e+03,   2.28800000e+03,\n",
       "         2.34700000e+03,   2.35700000e+03,   2.36500000e+03,\n",
       "         2.38700000e+03,   2.39600000e+03,   2.40300000e+03,\n",
       "         2.42900000e+03,   2.43800000e+03,   2.45800000e+03,\n",
       "         2.46800000e+03,   2.48400000e+03,   2.49300000e+03,\n",
       "         2.51200000e+03,   2.51900000e+03,   2.53000000e+03,\n",
       "         2.53100000e+03,   2.53900000e+03,   2.54700000e+03,\n",
       "         2.54900000e+03,   2.55700000e+03,   2.61200000e+03,\n",
       "         2.61900000e+03,   2.62100000e+03,   2.64000000e+03,\n",
       "         2.64100000e+03,   2.64300000e+03,   2.67600000e+03,\n",
       "         2.67700000e+03,   2.69500000e+03,   2.70200000e+03,\n",
       "         2.71800000e+03,   2.71900000e+03,   2.72200000e+03,\n",
       "         2.73900000e+03,   2.75300000e+03,   2.75800000e+03,\n",
       "         2.76500000e+03,   2.77900000e+03,   2.78100000e+03,\n",
       "         2.78600000e+03,   2.78700000e+03,   2.79300000e+03,\n",
       "         2.79800000e+03,   2.83900000e+03,   2.86800000e+03,\n",
       "         2.88000000e+03,   2.90700000e+03,   2.90900000e+03,\n",
       "         2.91500000e+03,   2.91800000e+03,   2.93900000e+03,\n",
       "         2.95200000e+03,   2.98600000e+03,   2.99400000e+03,\n",
       "         3.02100000e+03,   3.02400000e+03,   3.03000000e+03,\n",
       "         3.05300000e+03,   3.05600000e+03,   3.06100000e+03,\n",
       "         3.09900000e+03,   3.10400000e+03,   3.10900000e+03,\n",
       "         3.11100000e+03,   3.12100000e+03,   3.18900000e+03,\n",
       "         3.20100000e+03,   3.22100000e+03,   3.22400000e+03,\n",
       "         3.24400000e+03,   3.24500000e+03,   3.27700000e+03,\n",
       "         3.30000000e+03,   3.30700000e+03,   3.35400000e+03,\n",
       "         3.35500000e+03,   3.37400000e+03,   3.41900000e+03,\n",
       "         3.43600000e+03,   3.44900000e+03,   3.46000000e+03,\n",
       "         3.47200000e+03,   3.47400000e+03,   3.48900000e+03,\n",
       "         3.49700000e+03,   3.52900000e+03,   3.53200000e+03,\n",
       "         3.53400000e+03,   3.54600000e+03,   3.58600000e+03,\n",
       "         3.58800000e+03,   3.59000000e+03,   3.59100000e+03,\n",
       "         3.59700000e+03,   3.61500000e+03,   3.61600000e+03,\n",
       "         3.63700000e+03,   3.63800000e+03,   3.63900000e+03,\n",
       "         3.65100000e+03,   3.66100000e+03,   3.67800000e+03,\n",
       "         3.70500000e+03,   3.71100000e+03,   3.71200000e+03,\n",
       "         3.72300000e+03,   3.73200000e+03,   3.75600000e+03,\n",
       "         3.76200000e+03,   3.77400000e+03,   3.78400000e+03,\n",
       "         3.81400000e+03,   3.81600000e+03,   3.82800000e+03,\n",
       "         3.84400000e+03,   3.85400000e+03,   3.85900000e+03,\n",
       "         3.86000000e+03,   3.86900000e+03,   3.87500000e+03,\n",
       "         3.87700000e+03,   3.89200000e+03,   3.89700000e+03,\n",
       "         3.91200000e+03,   3.91800000e+03,   3.92100000e+03,\n",
       "         3.92400000e+03,   3.92500000e+03,   3.92900000e+03,\n",
       "         3.95200000e+03,   3.95400000e+03,   3.96900000e+03,\n",
       "         4.05500000e+03,   4.05700000e+03,   4.07300000e+03,\n",
       "         4.07500000e+03,   4.08300000e+03,   4.08600000e+03,\n",
       "         4.08800000e+03,   4.10100000e+03,   4.13800000e+03,\n",
       "         4.14600000e+03,   4.14700000e+03,   4.16700000e+03,\n",
       "         4.17100000e+03,   4.17600000e+03,   4.20900000e+03,\n",
       "         4.22300000e+03,   4.26200000e+03,   4.27000000e+03,\n",
       "         4.28700000e+03,   4.29600000e+03,   4.31000000e+03,\n",
       "         4.31100000e+03,   4.31900000e+03,   4.32200000e+03,\n",
       "         4.32600000e+03,   4.33100000e+03,   4.33300000e+03,\n",
       "         4.34400000e+03,   4.41100000e+03,   4.41800000e+03,\n",
       "         4.43900000e+03,   4.44700000e+03,   4.45300000e+03,\n",
       "         4.46200000e+03,   4.47300000e+03,   4.54100000e+03,\n",
       "         4.54200000e+03,   4.55700000e+03,   4.57200000e+03,\n",
       "         4.58100000e+03,   4.58200000e+03,   4.58700000e+03,\n",
       "         4.59700000e+03,   4.62300000e+03,   4.63300000e+03,\n",
       "         4.63800000e+03,   4.67300000e+03,   4.68300000e+03,\n",
       "         4.68800000e+03,   4.69600000e+03,   4.71200000e+03,\n",
       "         4.74700000e+03,   4.77300000e+03,   4.77500000e+03,\n",
       "         4.78000000e+03,   4.81800000e+03,   4.82100000e+03,\n",
       "         4.83600000e+03,   4.83700000e+03,   4.85200000e+03,\n",
       "         4.88000000e+03,   4.89300000e+03,   4.90300000e+03,\n",
       "         4.90500000e+03,   4.91400000e+03,   4.91700000e+03,\n",
       "         4.92600000e+03,   4.94700000e+03,   4.95000000e+03,\n",
       "         4.97100000e+03,   4.97400000e+03,   5.03900000e+03,\n",
       "         5.04000000e+03,   5.08200000e+03,   5.10600000e+03,\n",
       "         5.15500000e+03,   5.17400000e+03,   5.17600000e+03,\n",
       "         5.17900000e+03,   5.18100000e+03,   5.20200000e+03,\n",
       "         5.20900000e+03,   5.21600000e+03,   5.21900000e+03,\n",
       "         5.24500000e+03,   5.25100000e+03,   5.26900000e+03,\n",
       "         5.28000000e+03,   5.29100000e+03,   5.30900000e+03,\n",
       "         5.33400000e+03,   5.34600000e+03,   5.35200000e+03,\n",
       "         5.36100000e+03,   5.36400000e+03,   5.39400000e+03,\n",
       "         5.40300000e+03,   5.40500000e+03,   5.41600000e+03,\n",
       "         5.41700000e+03,   5.42700000e+03,   5.43700000e+03,\n",
       "         5.44000000e+03,   5.46500000e+03,   5.46700000e+03,\n",
       "         5.47100000e+03,   5.47400000e+03,   5.47500000e+03,\n",
       "         5.48800000e+03,   5.49700000e+03,   5.50200000e+03,\n",
       "         5.50900000e+03,   5.51400000e+03,   5.54100000e+03,\n",
       "         5.55200000e+03,   5.57400000e+03,   5.57700000e+03,\n",
       "         5.59500000e+03,   5.59600000e+03,   5.59700000e+03,\n",
       "         5.60400000e+03,   5.61600000e+03,   5.62000000e+03,\n",
       "         5.64900000e+03,   5.65300000e+03,   5.68500000e+03,\n",
       "         5.70500000e+03,   5.72200000e+03,   5.72700000e+03,\n",
       "         5.73200000e+03,   5.73600000e+03,   5.73700000e+03,\n",
       "         5.77000000e+03,   5.79700000e+03,   5.83400000e+03,\n",
       "         5.85400000e+03,   5.85500000e+03,   5.86000000e+03,\n",
       "         5.87600000e+03,   5.90100000e+03,   5.91600000e+03,\n",
       "         5.92800000e+03,   5.93800000e+03,   5.97400000e+03,\n",
       "         5.98000000e+03,   6.01600000e+03,   6.02700000e+03,\n",
       "         6.03100000e+03,   6.03400000e+03,   6.04700000e+03,\n",
       "         6.06400000e+03,   6.06800000e+03,   6.07200000e+03,\n",
       "         6.07400000e+03])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[-1,1:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_file = data_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cPickle.dump( list_file, open( \"list_file.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide Active in Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(list_file)):\n",
    "    active_user,pasive_user = cPickle.load( open( \"active_\"+ str(list_file[i]) +\".pkl\", \"rb\" ) ),cPickle.load( open( \"passive_\"+ str(list_file[i])+\".pkl\", \"rb\" ) )\n",
    "    ratio_train = (70 * movies)/100\n",
    "    ratio_test = movies-ratio_train\n",
    "    y = list(range(1,977))\n",
    "    np.random.shuffle(y)\n",
    "    train_rand,test_rand = array([0] + y[:int(ratio_train)]),array([0] + y[int(ratio_train):])\n",
    "    train,test = active_user[:,:,train_rand],active_user[:,:,test_rand]\n",
    "    cPickle.dump( train, open( \"train_\"+ str(i) +\".pkl\", \"wb\" ) )\n",
    "    cPickle.dump( test, open( \"test_\"+ str(i)+\".pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simlarity(rows,passive_users,user_list,k):\n",
    "    users = zeros((reviews,k))\n",
    "    for row1,passive_user,user in zip(rows,passive_users,users):\n",
    "        k_neighbr,idx,arr = np.zeros(passive_user.shape[0]),0,user_list\n",
    "#         print(passive_user.shape)\n",
    "        for row2 in passive_user[:,1:]:\n",
    "            temp1,temp2,temp3 = 0,0,0\n",
    "            mu1 = np.sum([row1], axis=1)[0]/row1.nonzero()[0].shape[0]\n",
    "            mu2 = np.sum([row2], axis=1)[0]/row2.nonzero()[0].shape[0]\n",
    "            for i in range(len(row1)):\n",
    "                if row1[i] is not 0 and row2[i] is not 0:\n",
    "                    temp1 += ((row1[i] - mu1) * (row2[i] - mu2))\n",
    "                    temp2 += (row1[i] - mu1) * (row1[i] - mu1)\n",
    "                    temp3 += (row2[i] - mu2) * (row2[i] - mu2)\n",
    "            k_neighbr[idx] = temp1/(sqrt(temp2) * sqrt(temp3))\n",
    "            idx+=1\n",
    "        user[:] = arr[k_neighbr.argsort()][-k:][::-1]\n",
    "    return np.unique(users.flatten())\n",
    "\n",
    "def k_neighbor(data,passive_user,k=20):\n",
    "#     users = matr1((data.shape[1],(reviews*k)+1))\n",
    "    users = matr1((data.shape[1],60))\n",
    "    for idx in range(1,data[0,1:,0].shape[0]+1):\n",
    "        temp,users[idx,0] = simlarity(data[:,idx],passive_user[:,1:],passive_user[0,:,0],k),data[0,idx,0]\n",
    "        users[idx,1:temp.shape[0]+1] = temp\n",
    "        idx += 1\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(list_file)):\n",
    "    passive_user = cPickle.load( open( \"passive_\"+ str(list_file[i])+\".pkl\", \"rb\" ) )\n",
    "    train,test = cPickle.load( open( \"train_\"+ str(i) +\".pkl\", \"rb\" ) ),cPickle.load( open( \"test_\"+ str(i)+\".pkl\", \"rb\" ) )\n",
    "    users_matrix = k_neighbor(train,passive_user,40)\n",
    "    cPickle.dump( users_matrix, open( \"users_matrix_\"+ str(i)+\".pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X_train,X_test | Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, activation='relu', input_dim=5))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.compile(optimizer='rmsprop',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('./mod/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_error(model,train_x,train_y,test_x,test_y):\n",
    "    lst = []\n",
    "    list_err = []\n",
    "    for i in range(len(train_x)):\n",
    "        \n",
    "        try:\n",
    "            Tr_X = train_x[i]\n",
    "            Tr_Y = np.reshape(train_y[i][:,-1],(train_y[i][:,-1].shape[0],1))\n",
    "            Tt_X = test_x[i]\n",
    "            Tt_Y = np.reshape(test_y[i][:,-1],(test_y[i][:,-1].shape[0],1))\n",
    "            model.load_weights('./mod/model.h5')\n",
    "#             model.fit(Tr_X,Tr_Y,epochs=500, batch_size=70, verbose= 0 )\n",
    "            model.fit(Tr_X,Tr_Y,epochs=150, batch_size=train_x[i].shape[0], verbose= 0 )\n",
    "\n",
    "            \n",
    "            err,tp,fp,fn,tn = 0.0,0.0,0.0,0.0,0.0\n",
    "        \n",
    "            predicted = model.predict(Tt_X, batch_size=Tt_X.shape[0])\n",
    "            for Pred,Actual in zip(predicted,Tt_Y):\n",
    "                if Pred >= 7 and Actual >= 7:\n",
    "                    tp+=1.0\n",
    "                elif Pred < 7 and Actual >= 7:\n",
    "                    fn+=1.0\n",
    "                elif Pred >= 7 and Actual < 7:\n",
    "                    fp+=1.0\n",
    "                else:\n",
    "                    tn+=1.0\n",
    "        \n",
    "            prec = tp/(tp+fp)\n",
    "            recal = tp/(tp+fn)\n",
    "            f_meas = (2*recal*prec)/(recal + prec)\n",
    "            err = np.absolute((predicted - Tt_Y)).mean(axis=0)[0]\n",
    "            list_err.append([err,prec,recal,f_meas])\n",
    "        \n",
    "        except:\n",
    "            print(\"error : \",i)\n",
    "                    \n",
    "    list_err = array(list_err)\n",
    "    \n",
    "    return np.mean(list_err,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datashaping(users_matrix,train,passive_user,id_idx):\n",
    "    X_train,Y_train = [],[]\n",
    "    for row_idx in range(1,users_matrix[1:].shape[0]+1):\n",
    "        x_train,y_train = [],[]\n",
    "#         print(\"progress :: user completed :- \", row_idx)\n",
    "        temp = train[0,row_idx,:].nonzero()[0]\n",
    "        movie_pool = train[0,0,temp]\n",
    "        for idx in range(1,movie_pool[1:].shape[0]+1):\n",
    "            for usr in users_matrix[row_idx,1:]:\n",
    "                if usr > 0 and passive_user[0,id_idx[usr],int(movie_pool[idx])] > 0 :\n",
    "                    x_train.append(passive_user[:,id_idx[usr],int(movie_pool[idx])])\n",
    "                    y_train.append(train[:,row_idx,int(temp[idx])])\n",
    "\n",
    "        X_train.append(array(x_train))\n",
    "        Y_train.append(array(y_train))\n",
    "        \n",
    "    return X_train,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI 0\n",
      "error :  34\n",
      "HI 1\n",
      "HI 2\n",
      "HI 3\n",
      "HI 4\n",
      "error :  6\n",
      "HI 5\n",
      "HI 6\n",
      "HI 7\n",
      "HI 8\n",
      "error :  24\n",
      "error :  32\n",
      "HI 9\n"
     ]
    }
   ],
   "source": [
    "lst_err = []\n",
    "list_file = cPickle.load( open( \"list_file.pkl\", \"rb\" ) )\n",
    "for i in range(len(list_file)):\n",
    "    print(\"HI\",i)\n",
    "    passive_user = cPickle.load( open( \"passive_\"+ str(list_file[i])+\".pkl\", \"rb\" ) )\n",
    "    train,test = cPickle.load( open( \"train_\"+ str(i) +\".pkl\", \"rb\" ) ),cPickle.load( open( \"test_\"+ str(i)+\".pkl\", \"rb\" ) )\n",
    "    users_matrix = cPickle.load( open( \"users_matrix_\"+ str(i) +\".pkl\", \"rb\" ) )\n",
    "    passive_user[:,1:,1:] = (passive_user[:,1:,1:])\n",
    "    train[:,1:,1:] = (train[:,1:,1:])\n",
    "    test[:,1:,1:] = (test[:,1:,1:])\n",
    "    id_idx = {}\n",
    "    for idx,ele in enumerate(passive_user[0,:,0]):\n",
    "        id_idx[ele] = idx\n",
    "    \n",
    "    train_x,train_y = datashaping(users_matrix,train,passive_user,id_idx)\n",
    "    test_x,test_y = datashaping(users_matrix,test,passive_user,id_idx)\n",
    "    \n",
    "    lst_err.append(train_error(model,train_x,train_y,test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst_err = cPickle.load( open( \"lst_err.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cPickle.dump( lst_err, open( \"lst_err.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_file = cPickle.load( open( \"list_file.pkl\", \"rb\" ) )\n",
    "passive_user = cPickle.load( open( \"passive_\"+ str(list_file[0])+\".pkl\", \"rb\" ) )\n",
    "train,test = cPickle.load( open( \"train_\"+ str(0) +\".pkl\", \"rb\" ) ),cPickle.load( open( \"test_\"+ str(0)+\".pkl\", \"rb\" ) )\n",
    "users_matrix = cPickle.load( open( \"users_matrix_\"+ str(0) +\".pkl\", \"rb\" ) )\n",
    "passive_user[:,1:,1:] = (passive_user[:,1:,1:])\n",
    "train[:,1:,1:] = (train[:,1:,1:])\n",
    "test[:,1:,1:] = (test[:,1:,1:])\n",
    "id_idx = {}\n",
    "for idx,ele in enumerate(passive_user[0,:,0]):\n",
    "    id_idx[ele] = idx\n",
    "    \n",
    "train_x,train_y = datashaping(users_matrix,train,passive_user,id_idx)\n",
    "test_x,test_y = datashaping(users_matrix,test,passive_user,id_idx)\n",
    "# train_error(model,train_x,train_y,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    lst_err[i][0] = lst_err[i][0] * 51\n",
    "lst_err[-1][0] = lst_err[-1][0] * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 2.35394782,  0.90462718,  0.89929684,  0.89444511]),\n",
       " array([ 2.22143838,  0.91288258,  0.88881221,  0.88991207]),\n",
       " array([ 2.23555299,  0.91531156,  0.88135118,  0.89129421]),\n",
       " array([ 2.3889509 ,  0.88119379,  0.8736491 ,  0.86369474]),\n",
       " array([ 2.31112709,  0.85447569,  0.90416508,  0.86253659]),\n",
       " array([ 2.26715263,  0.89485271,  0.88323387,  0.8828301 ]),\n",
       " array([ 2.51156562,  0.83280605,  0.9085413 ,  0.85866783]),\n",
       " array([ 2.21583983,  0.93055994,  0.904133  ,  0.9151052 ]),\n",
       " array([ 2.30062218,  0.92500828,  0.88813217,  0.90060183]),\n",
       " array([ 2.25068063,  0.94350535,  0.90116284,  0.91434626])]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.04615584,  0.90462718,  0.89929684,  0.89444511]),\n",
       " array([ 0.04355762,  0.91288258,  0.88881221,  0.88991207]),\n",
       " array([ 0.04383437,  0.91531156,  0.88135118,  0.89129421]),\n",
       " array([ 0.04684217,  0.88119379,  0.8736491 ,  0.86369474]),\n",
       " array([ 0.04531622,  0.85447569,  0.90416508,  0.86253659]),\n",
       " array([ 0.04445397,  0.89485271,  0.88323387,  0.8828301 ]),\n",
       " array([ 0.04924638,  0.83280605,  0.9085413 ,  0.85866783]),\n",
       " array([ 0.04344784,  0.93055994,  0.904133  ,  0.9151052 ]),\n",
       " array([ 0.04511024,  0.92500828,  0.88813217,  0.90060183]),\n",
       " array([ 0.09002723,  0.94350535,  0.90116284,  0.91434626])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"neural_network_10.csv\", lst_err, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1,activation='linear',input_dim=5))\n",
    "model.compile(optimizer='rmsprop',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('./mod/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "# import matplotlib as plt\n",
    "from random import sample\n",
    "from numpy import zeros\n",
    "from math import sqrt\n",
    "import _pickle as cPickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = cPickle.load( open( \"train_\"+ str(2)+\".pkl\", \"rb\" ) )\n",
    "test = cPickle.load( open( \"test_\"+ str(2)+\".pkl\", \"rb\" ) )\n",
    "passive = cPickle.load( open( \"passive_\"+ str(102)+\".pkl\", \"rb\" ) )\n",
    "list_file = cPickle.load( open( \"list_file.pkl\", \"rb\" ) )\n",
    "# train = cPickle.load( open( \"train_v1.pkl\", \"rb\" ) )\n",
    "# test = cPickle.load( open( \"test_v1.pkl\", \"rb\" ) )\n",
    "# passive = cPickle.load( open( \"pasive_v1.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 51, 102, 153, 204, 255, 306, 357, 408, 459]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizer(data):\n",
    "    for dim in range(data.shape[0]):\n",
    "        for row in range(1,data.shape[1]):\n",
    "            for ele in range(1,data.shape[2]):\n",
    "                if abs(data[dim,row,ele] - 0) < 1e-10:\n",
    "                    data[dim,row,ele] = 0.0\n",
    "                elif abs(data[dim,row,ele] - 1) < 1e-10:\n",
    "                    data[dim,row,ele] = 1.0\n",
    "                elif abs(data[dim,row,ele] - 2) < 1e-10 or abs(data[dim,row,ele] - 3) < 1e-10 or abs(data[dim,row,ele] - 4) < 1e-10:\n",
    "                    data[dim,row,ele] = 2.0\n",
    "                elif abs(data[dim,row,ele] - 5) < 1e-10 or abs(data[dim,row,ele] - 6) < 1e-10 or abs(data[dim,row,ele] - 7) < 1e-10:\n",
    "                    data[dim,row,ele] = 3.0\n",
    "                elif abs(data[dim,row,ele] - 8) < 1e-10 or abs(data[dim,row,ele] - 9) < 1e-10 or abs(data[dim,row,ele] - 10) < 1e-10:\n",
    "                    data[dim,row,ele] = 4.0\n",
    "                elif abs(data[dim,row,ele] - 11) < 1e-10 or abs(data[dim,row,ele] - 12) < 1e-10 or abs(data[dim,row,ele] - 13) < 1e-10:\n",
    "                    data[dim,row,ele] = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalizer(train)\n",
    "normalizer(test)\n",
    "normalizer(passive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reputation = []\n",
    "for t_idx in range(1,passive.shape[1]):\n",
    "    temp,temp_idx = 0,0\n",
    "    for p_idx in range(1,passive.shape[1]):\n",
    "        if t_idx is p_idx:\n",
    "            continue\n",
    "        nonzero_arow, nonzero_prow = passive[-1,t_idx].nonzero()[0], passive[-1,p_idx].nonzero()[0]\n",
    "        common_idx = np.intersect1d(nonzero_arow, nonzero_prow)\n",
    "        reliable,Ra = 0,0\n",
    "        if common_idx[1:].shape[0] > 0: \n",
    "            mx,my = passive[-1,1,common_idx[1:]].mean(),passive[-1,1,common_idx[1:]].mean()\n",
    "            rae,r_dash = [],[]\n",
    "            for ele in common_idx[1:]:\n",
    "                py = (mx - my) + passive[-1,p_idx,ele]\n",
    "                diff = abs(py - passive[-1,t_idx,ele])\n",
    "\n",
    "                if diff >= 0 and diff <= 0.5 :\n",
    "                    rae.append(2.0)\n",
    "                elif diff > 0.5 and diff <= 1.0:\n",
    "                    rae.append(1.0)\n",
    "                elif diff > 1.0 and diff <= 1.5:\n",
    "                    rae.append(0.0)\n",
    "                elif diff > 1.5 and diff <= 2.0:\n",
    "                    rae.append(-1.0)\n",
    "                elif diff > 2.0 :\n",
    "                    rae.append(-2.0)\n",
    "\n",
    "                p_dash = (mx - my) + passive[-1,t_idx,ele]\n",
    "                diff = abs(p_dash - passive[-1,p_idx,ele])\n",
    "                if diff > 1.0 and diff <= 1.5:\n",
    "                    r_dash.append(0.0)\n",
    "\n",
    "            rae,S_dash_zero = array(rae),len(r_dash)\n",
    "            Sap,San,S_zero = rae[rae > 0], rae[rae < 0], rae[abs(rae - 0) < 1e-10].shape[0]\n",
    "            Nap,Nan = Sap.shape[0], San.shape[0]\n",
    "            \n",
    "            Ra = 1/rae.shape[0] * (Nap - Nan)/(Nap + Nan + 2)\n",
    "            if rae.shape[0] > 0:\n",
    "                reliable = 1 - ((S_zero + S_dash_zero)/(rae.shape[0] + (rae.shape[0])))\n",
    "        else:\n",
    "            reliable,Ra = 1, 0\n",
    "        temp += reliable * Ra\n",
    "        temp_idx += 1\n",
    "    reputation.append(temp/temp_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matr(shp):\n",
    "    temp = zeros(shp)\n",
    "    temp[0,:] = range(shp[1])\n",
    "    temp[:,0] = range(shp[0])\n",
    "    return temp\n",
    "\n",
    "def simlarity(row1,passive_user,k):\n",
    "    k_neighbr,idx,arr = np.zeros(passive_user.shape[0]),0,passive_user[:,0]\n",
    "\n",
    "    for row2 in passive_user[:,1:]:\n",
    "        temp1,temp2,temp3 = 0,0,0\n",
    "        mu1 = np.sum([row1], axis=1)[0]/row1.nonzero()[0].shape[0]\n",
    "        mu2 = np.sum([row2], axis=1)[0]/row2.nonzero()[0].shape[0]\n",
    "        for i in range(len(row1)):\n",
    "            if abs(row1[i] - 0) > 1e-10 and abs(row2[i] - 0) > 1e-10:\n",
    "                temp1 += ((row1[i] - mu1) * (row2[i] - mu2))\n",
    "                temp2 += (row1[i] - mu1) * (row1[i] - mu1)\n",
    "                temp3 += (row2[i] - mu2) * (row2[i] - mu2)\n",
    "        \n",
    "        k_neighbr[idx] = 0 if abs(temp2 - 0) < 1e-10 or abs(temp3 - 0) < 1e-10 else temp1/(sqrt(temp2) * sqrt(temp3))\n",
    "        idx+=1\n",
    "    \n",
    "    return arr[k_neighbr.argsort()][-k:][::-1]\n",
    "\n",
    "def k_neighbor(data,passive_user,k=50):\n",
    "    users,idx = matr((data.shape[0],k+1)),1\n",
    "    for user in data[1:,1:]:\n",
    "        users[idx,1:],users[idx,0] = simlarity(user,passive_user[1:],k),data[idx,0]\n",
    "        idx += 1    \n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relation_matrix = k_neighbor(train[-1],passive[-1],80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diffmapping(diff,rea,sat,unsat):\n",
    "\n",
    "    if diff >= 0 and diff <= 0.5 :\n",
    "        rae.append(2.0)\n",
    "        sat.append(1)\n",
    "        unsat.append(0)\n",
    "    elif diff > 0.5 and diff <= 1.0:\n",
    "        rae.append(1.0)\n",
    "        sat.append((1.0 + 2.0)/4)\n",
    "        unsat.append((1 - (3.0/4)))\n",
    "    elif diff > 1.0 and diff <= 1.5:\n",
    "        rae.append(0.0)\n",
    "        sat.append((0.0 + 2.0)/4)\n",
    "        unsat.append((1 - (2.0/4)))\n",
    "    elif diff > 1.5 and diff <= 2.0:\n",
    "        rae.append(-1.0)\n",
    "        sat.append((-1.0 + 2.0)/4)\n",
    "        unsat.append((1 - (1.0/4)))\n",
    "    elif diff > 2.0 :\n",
    "        rae.append(-2.0)\n",
    "        sat.append(0)\n",
    "        unsat.append(1)\n",
    "        \n",
    "    return rae,sat,unsat\n",
    "\n",
    "def satisfy(sat,sat2,unsat,unsat2):\n",
    "    \n",
    "    sns,sus,unu,uuu,snu,suu,uns,uus = 0,0,0,0,0,0,0,0\n",
    "    for s1,s2,u1,u2 in zip(sat,sat2,unsat,unsat2):\n",
    "\n",
    "        sns += min(s1,s2)\n",
    "        sus += max(s1,s2)\n",
    "        unu += min(u1,u2)\n",
    "        uuu += max(u1,u2)\n",
    "        snu += min(s1,u2)\n",
    "        suu += max(s1,u2)\n",
    "        uns += min(u1,s2)\n",
    "        uus += max(u1,s2)   \n",
    "        \n",
    "    SS = 0 if abs(sus-0) < 1e-10 else sns/sus    \n",
    "    UU = 0 if abs(uuu-0) < 1e-10 else unu/uuu\n",
    "    SU = 0 if abs(suu-0) < 1e-10 else snu/suu\n",
    "    US = 0 if abs(uus-0) < 1e-10 else uns/uus \n",
    "    \n",
    "    agr,disagr = (SS + UU)/2, (SU + US)/2\n",
    "    rec = (1 - disagr)*agr\n",
    "    \n",
    "    return rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trust = matr(relation_matrix.shape)\n",
    "trust[:,0] = relation_matrix[:,0]\n",
    "\n",
    "passive_dict = {}\n",
    "for idx,value in enumerate(passive[-1,:,0]):\n",
    "    passive_dict[value] = idx\n",
    "\n",
    "for t_idx in range(1,train.shape[1]):\n",
    "    recip = []\n",
    "    for r_idx in range(1,relation_matrix.shape[1]):\n",
    "        \n",
    "        p_idx = passive_dict[relation_matrix[t_idx,r_idx]]\n",
    "        nonzero_arow, nonzero_prow = train[-1,t_idx].nonzero()[0], passive[-1,p_idx].nonzero()[0]\n",
    "        common_idx = np.intersect1d(nonzero_arow, nonzero_prow)\n",
    "        reliable,rec = 0,0\n",
    "        if common_idx[1:].shape[0] > 0: \n",
    "\n",
    "            mx,my = train[-1,1,common_idx[1:]].mean(),passive[-1,1,common_idx[1:]].mean()\n",
    "            rae,r_dash,sat,unsat,sat2,unsat2 = [],[],[],[],[],[]\n",
    "            for ele in common_idx[1:]:\n",
    "                py = (mx - my) + passive[-1,p_idx,ele]\n",
    "                diff = abs(py - train[-1,t_idx,ele])\n",
    "                rae,sat,unsat = diffmapping(diff,rae,sat,unsat)\n",
    "                p_dash = (mx - my) + train[-1,t_idx,ele]\n",
    "                diff = abs(p_dash - passive[-1,p_idx,ele])\n",
    "                r_dash,sat2,unsat2 = diffmapping(diff,r_dash,sat2,unsat2)\n",
    "            \n",
    "            rec = satisfy(sat,sat2,unsat,unsat2)\n",
    "            \n",
    "            rae,S_dash_zero = array(rae), len(r_dash) \n",
    "            S_zero = rae[abs(rae - 0) < 1e-10].shape[0]\n",
    "            if rae.shape[0] > 0:\n",
    "                reliable = 1 - ((S_zero + S_dash_zero)/(rae.shape[0] + (rae.shape[0])))\n",
    "        else:\n",
    "            reliable = 1\n",
    "        \n",
    "        trust[t_idx,r_idx] = reliable * rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 81)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 81)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From 80 nearest neighbor choosing top 50 via trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trust_50,relation_matrix_50 = matr((trust.shape[0],51)),matr((relation_matrix.shape[0],51))\n",
    "trust_50[:,0],relation_matrix_50[:,0] = trust[:,0],relation_matrix[:,0]\n",
    "for idx in range(1,relation_matrix.shape[0]):\n",
    "    row_relation,row_trust,alpha = relation_matrix[idx,1:],trust[idx,1:],trust[idx,1:].argsort()\n",
    "    relation_matrix_50[idx,1:],trust_50[idx,1:] = row_relation[alpha][-50:][::-1],row_trust[alpha][-50:][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3rd phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_dict = {}\n",
    "for idx,value in enumerate(passive[-1,0,:]):\n",
    "    movie_dict[value] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def passive_details(user_id,movie_id,movie_dict = movie_dict,passive_dataset = passive):\n",
    "    return passive_dataset[:,user_id,movie_dict[movie_id]]\n",
    "\n",
    "def value_details(T_idx,P_idx,reputation,trust_50,relation_matrix_50,passive_dict):\n",
    "    if P_idx in relation_matrix_50[T_idx,1:]:\n",
    "        idx = np.where(relation_matrix_50[T_idx] == P_idx)[0][0]\n",
    "        return trust_50[T_idx,idx], True\n",
    "    else:\n",
    "        return reputation[P_idx - 1], False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Fr_funtion(train,passive,trust_50,relation_matrix_50,passive_dict):\n",
    "    Train_user_list = []\n",
    "    Train_y_list = []\n",
    "    for T_idx in range(1,train.shape[1]):\n",
    "    #     Tracer()()\n",
    "        rated_movies_idx = train[-1,T_idx,1:].nonzero()[0] + 1\n",
    "        if abs(len(rated_movies_idx) - 0) < 1e-10:\n",
    "                continue\n",
    "        Fr_list,Fx_list = [],[]\n",
    "        for movie_idx in rated_movies_idx:\n",
    "            Tr,Rep,Tr_sum,Rep_sum = array([0.0,0,0,0]),array([0.0,0,0,0]),array([0.0,0,0,0]),array([0.0,0,0,0])\n",
    "            movie_train_id = train[-1,0,movie_idx]\n",
    "            for P_idx in range(1,passive.shape[1]):\n",
    "                trusted_rating = passive_details(P_idx,movie_train_id)[:-1]\n",
    "                value,trt = value_details(T_idx,P_idx,reputation,trust_50,relation_matrix_50,passive_dict)\n",
    "                if 0 in trusted_rating:\n",
    "                    continue\n",
    "                if trt is True:\n",
    "                    Tr += value*trusted_rating\n",
    "                    Tr_sum += value\n",
    "                else:\n",
    "                    Rep += value*trusted_rating\n",
    "                    Rep_sum += value\n",
    "\n",
    "            if 0 in Tr_sum and 0 in Rep_sum: \n",
    "                pass\n",
    "            elif not(0 in Tr_sum) and not(0 in Rep_sum):\n",
    "                Fr_list.append((0.6*Tr/Tr_sum) + (0.4*(Rep)/Rep_sum))     \n",
    "                Fx_list.append(train[-1,T_idx,movie_idx])\n",
    "            elif not(0 in Tr_sum) and 0 in Rep_sum:    \n",
    "                Fr_list.append((0.6*Tr/Tr_sum))\n",
    "                Fx_list.append(train[-1,T_idx,movie_idx])\n",
    "            elif 0 in Tr_sum and not(0 in Rep_sum):\n",
    "                Fr_list.append((0.6*Rep/Rep_sum))\n",
    "                Fx_list.append(train[-1,T_idx,movie_idx])\n",
    "        Train_user_list.append(array(Fr_list))\n",
    "        Train_y_list.append(array(Fx_list))\n",
    "    return Train_user_list,Train_y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "semi_train,semi_y_train = Fr_funtion(train,passive,trust_50,relation_matrix_50,passive_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "semi_test,semi_y_test = Fr_funtion(test,passive,trust_50,relation_matrix_50,passive_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cPickle.dump( semi_train, open( \"semi_train.pkl\", \"wb\" ) )\n",
    "# cPickle.dump( semi_y_train, open( \"semi_y_train.pkl\", \"wb\" ) )\n",
    "# cPickle.dump( semi_test, open( \"semi_test.pkl\", \"wb\" ) )\n",
    "# cPickle.dump( semi_y_test, open( \"semi_y_test.pkl\", \"wb\" ) )\n",
    "\n",
    "semi_train = cPickle.load( open( \"semi_train.pkl\", \"rb\" ) )\n",
    "semi_y_train = cPickle.load( open( \"semi_y_train.pkl\", \"rb\" ) )\n",
    "semi_test = cPickle.load( open( \"semi_test.pkl\", \"rb\" ) )\n",
    "semi_y_test = cPickle.load( open( \"semi_y_test.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_x,Test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, activation='relu', input_dim=4))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "model.compile(optimizer='rmsprop',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_error(model,train_x,train,test_x,test):\n",
    "#     Tracer()()\n",
    "    lst = []\n",
    "    list_err = []\n",
    "    for i in range(len(train_x)):\n",
    "        try:\n",
    "            Tr_X = array(train_x[i])\n",
    "            Tr_Y = array(train[i])\n",
    "            Tt_X = array(test_x[i])\n",
    "            Tt_Y = array(test[i])\n",
    "            model.load_weights('model.h5')\n",
    "            model.fit(Tr_X, Tr_Y, epochs=150, batch_size=int(Tr_X.shape[0]*0.7), verbose=0)\n",
    "\n",
    "            err,tp,fp,fn,tn = 0.0,0.0,0.0,0.0,0.0\n",
    "        \n",
    "            predicted = model.predict(Tt_X, batch_size=Tt_X.shape[0])\n",
    "            for Pred,Actual in zip(predicted,Tt_Y):\n",
    "#                 print(Pred,Actual)\n",
    "                if Pred >= 3 and Actual >= 3:\n",
    "                    tp+=1.0\n",
    "                elif Pred < 3 and Actual >= 3:\n",
    "                    fn+=1.0\n",
    "                elif Pred >= 3 and Actual < 3:\n",
    "                    fp+=1.0\n",
    "                else:\n",
    "                    tn+=1.0\n",
    "            \n",
    "            prec = tp/(tp+fp)\n",
    "            recal = tp/(tp+fn)\n",
    "            f_meas = (2*recal*prec)/(recal + prec)\n",
    "            err = np.absolute((predicted - Tt_Y)).mean(axis=0)[0]\n",
    "            list_err.append([err,prec,recal,f_meas])\n",
    "        \n",
    "        except:\n",
    "            print(\"error : \",i)\n",
    "                    \n",
    "    list_err = array(list_err)\n",
    "    \n",
    "    return np.mean(list_err,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = train_error(model,semi_train,semi_y_train,semi_test,semi_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.18482629,  0.93107382,  0.83312258,  0.86750932])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.36335655,  0.93900371,  0.84379337,  0.87377116])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lst_err = []\n",
    "# list_file = cPickle.load( open( \"list_file.pkl\", \"rb\" ) )\n",
    "# for i in range(len(list_file)):\n",
    "#     print(\"HI\",i)\n",
    "#     lst_err.append(train_error(model,semi_train,semi_y_train,semi_test,semi_y_test))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(array(semi_test[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(semi_y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.random.random((1000, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is LENOVO\n",
      " Volume Serial Number is 04A4-0078\n",
      "\n",
      " Directory of D:\\old_laptop_data\\linux_desktop\\recom\\proj3\n",
      "\n",
      "16-09-2017  01.33 AM    <DIR>          .\n",
      "16-09-2017  01.33 AM    <DIR>          ..\n",
      "09-09-2017  01.24 PM    <DIR>          .ipynb_checkpoints\n",
      "10-09-2017  02.53 PM             8,794 dummy.xlsx\n",
      "29-08-2017  05.02 PM                32 list_file.pkl\n",
      "16-09-2017  01.31 AM            13,088 model.h5\n",
      "13-09-2017  03.01 PM        16,960,884 pasive_v1.pkl\n",
      "29-08-2017  05.01 PM        16,960,884 passive_0.pkl\n",
      "29-08-2017  05.01 PM        16,960,884 passive_102.pkl\n",
      "29-08-2017  05.01 PM        16,960,884 passive_153.pkl\n",
      "29-08-2017  05.01 PM        16,960,884 passive_204.pkl\n",
      "29-08-2017  05.01 PM        16,960,884 passive_255.pkl\n",
      "29-08-2017  05.01 PM        16,960,884 passive_306.pkl\n",
      "29-08-2017  05.01 PM        16,960,884 passive_357.pkl\n",
      "29-08-2017  05.01 PM        16,960,884 passive_408.pkl\n",
      "29-08-2017  05.01 PM        17,976,964 passive_459.pkl\n",
      "29-08-2017  05.01 PM        16,960,884 passive_51.pkl\n",
      "15-09-2017  06.14 PM            21,090 semi_test.pkl\n",
      "15-09-2017  06.14 PM            45,179 semi_train.pkl\n",
      "15-09-2017  06.14 PM             6,834 semi_y_test.pkl\n",
      "15-09-2017  06.14 PM            12,869 semi_y_train.pkl\n",
      "28-08-2017  04.03 PM           611,683 test_0.pkl\n",
      "28-08-2017  04.03 PM           611,683 test_1.pkl\n",
      "28-08-2017  04.03 PM           611,683 test_2.pkl\n",
      "28-08-2017  04.03 PM           611,683 test_3.pkl\n",
      "28-08-2017  04.03 PM           611,683 test_4.pkl\n",
      "28-08-2017  04.03 PM           611,683 test_5.pkl\n",
      "28-08-2017  04.03 PM           611,683 test_6.pkl\n",
      "28-08-2017  04.03 PM           611,683 test_7.pkl\n",
      "28-08-2017  04.03 PM           611,683 test_8.pkl\n",
      "28-08-2017  04.03 PM           305,923 test_9.pkl\n",
      "13-09-2017  03.01 PM           611,683 test_v1.pkl\n",
      "28-08-2017  04.03 PM         1,422,883 train_0.pkl\n",
      "28-08-2017  04.03 PM         1,422,883 train_1.pkl\n",
      "28-08-2017  04.03 PM         1,422,883 train_2.pkl\n",
      "28-08-2017  04.03 PM         1,422,883 train_3.pkl\n",
      "28-08-2017  04.03 PM         1,422,883 train_4.pkl\n",
      "28-08-2017  04.03 PM         1,422,883 train_5.pkl\n",
      "28-08-2017  04.03 PM         1,422,883 train_6.pkl\n",
      "28-08-2017  04.03 PM         1,422,883 train_7.pkl\n",
      "28-08-2017  04.03 PM         1,422,883 train_8.pkl\n",
      "28-08-2017  04.03 PM           711,523 train_9.pkl\n",
      "13-09-2017  03.01 PM         1,422,883 train_v1.pkl\n",
      "16-09-2017  01.33 AM            23,225 version_01.ipynb\n",
      "              41 File(s)    209,080,021 bytes\n",
      "               3 Dir(s)  836,399,800,320 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_file = cPickle.load( open( \"list_file.pkl\", \"rb\" ) )\n",
    "for idx,file_num in enumerate(list_file):\n",
    "    passive = cPickle.load( open( \"passive_\" + str(file_num) + \".pkl\", \"rb\" ) )\n",
    "    train = cPickle.load( open( \"train_\" + str(idx) + \".pkl\", \"rb\" ) )\n",
    "    test = cPickle.load( open( \"test_\" + str(idx) + \".pkl\", \"rb\" ) )\n",
    "    \n",
    "    normalizer(train)\n",
    "    normalizer(test)\n",
    "    normalizer(passive)\n",
    "    \n",
    "    new_train = zeros((train.shape[1]-1,(train.shape[2]-1)*5))\n",
    "    new_test = zeros((test.shape[1]-1,(test.shape[2]-1)*5))\n",
    "    new_passive = zeros((passive.shape[1]-1,(passive.shape[2]-1)*5))\n",
    "    \n",
    "    for i in range(1,train.shape[1]):\n",
    "        for j in range(1,train.shape[2]):\n",
    "            new_train[i-1,(j-1)*5:(j)*5] = train[:,i,j]\n",
    "\n",
    "    for i in range(1,test.shape[1]):\n",
    "        for j in range(1,test.shape[2]):\n",
    "            new_test[i-1,(j-1)*5:(j)*5] = test[:,i,j]\n",
    "\n",
    "    for i in range(1,passive.shape[1]):\n",
    "        for j in range(1,passive.shape[2]):\n",
    "            new_passive[i-1,(j-1)*5:(j)*5] = passive[:,i,j]\n",
    "    \n",
    "    np.savetxt(\"./shweta/Train_\"+str(idx)+\".csv\", new_train, delimiter=\",\")\n",
    "    np.savetxt(\"./shweta/Test1_\"+str(idx)+\".csv\", new_test, delimiter=\",\")\n",
    "    np.savetxt(\"./shweta/Passive1_\"+str(idx)+\".csv\", new_passive, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
